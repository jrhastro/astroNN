{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Investigating using Convolutional Networks on Weak Lensing data\n",
    "=============\n",
    "\n",
    "Adapted from 4_conv_WL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MultipleLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reorganize the code a bit by putting the function definitions first.\n",
    "def rebin(a, shape):\n",
    "    sh = shape[0],a.shape[0]//shape[0],shape[1],a.shape[1]//shape[1]\n",
    "    return a.reshape(sh).mean(-1).mean(1)\n",
    "\n",
    "def getFITS(imagename):\n",
    "    filename = whereami + '/' + path + imagename\n",
    "    f = fits.open(filename)\n",
    "    dataout = f[0].data\n",
    "    \n",
    "    return dataout\n",
    "\n",
    "def read_WL(path,display=None):\n",
    "    # this is a version to look at sigma8\n",
    "    labels=['750', '850']\n",
    "    imgs = np.zeros([2048/degrade, 2048/degrade, nct, len(labels)])\n",
    "    for j, label in enumerate(labels):\n",
    "        for i in range(nct):\n",
    "            filename = whereami + '/' + path + 'smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.'+label+'_4096xy_000'+ np.str(i+1) +'r_0029p_0100z_og.gre.fit'\n",
    "            if display: print(\"i: %d  j: %d  name: %s\" % (i, j, 'smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.'+label+'_4096xy_000'+ np.str(i+1) +'r_0029p_0100z_og.gre.fit'))\n",
    "            f = fits.open(filename)\n",
    "            imgs[:,:,i,j]=rebin(f[0].data, [2048/degrade, 2048/degrade])\n",
    "            \n",
    "    return imgs, labels\n",
    "\n",
    "def slice_data(data, labels, exp_cut, exp_nshift):\n",
    "    labels=['750', '850']\n",
    "    # how many panels across\n",
    "    npanelx = 2**exp_cut\n",
    "    # and how big are they?\n",
    "    panelw = 2048/(degrade*npanelx)\n",
    "    # how many shifted panels?\n",
    "    nshift = 2**exp_nshift -1\n",
    "    # and what are the shifts?\n",
    "    shiftw =  panelw/2**exp_nshift\n",
    "    # with 4 rotations, and 2 shifts, we have\n",
    "    imgs = np.zeros([panelw, panelw, nct,(npanelx**2 +(npanelx-1)**2*nshift**2)*8, len(labels)])\n",
    "    # let's figure out where the centers are, and save that data\n",
    "    x_centers = np.zeros([nct,(npanelx**2 +(npanelx-1)**2*nshift**2)*8, len(labels)])\n",
    "    y_centers = np.zeros([nct,(npanelx**2 +(npanelx-1)**2*nshift**2)*8, len(labels)])\n",
    "    for j, label in enumerate(labels):\n",
    "        for i in range(nct):\n",
    "            q=0\n",
    "            for k in range(npanelx):\n",
    "                for l in range(npanelx):\n",
    "                    for r in range(4):\n",
    "                        imgs[:,:,i,q,j] = np.rot90(data[panelw*k:panelw*(k+1),panelw*l:panelw*(l+1),i, j], r)\n",
    "                        x_centers[i,q,j] = (panelw*k+panelw*(k+1))/2.\n",
    "                        y_centers[i,q,j] = (panelw*l+panelw*(l+1))/2.\n",
    "                        q+=1\n",
    "                        imgs[:,:,i,q,j] = np.fliplr(np.rot90(data[panelw*k:panelw*(k+1),panelw*l:panelw*(l+1),i, j], r))\n",
    "                        x_centers[i,q,j] = (panelw*k+panelw*(k+1))/2.\n",
    "                        y_centers[i,q,j] = (panelw*l+panelw*(l+1))/2.\n",
    "                        q+=1\n",
    "            for k in range(npanelx-1):\n",
    "                for l in range(npanelx-1):\n",
    "                    for m in range(nshift):\n",
    "                        for n in range(nshift):\n",
    "                            for r in range(4):\n",
    "                                imgs[:,:,i,q,j] = np.rot90(data[panelw*k+m*shiftw:panelw*(k+1)+m*shiftw,panelw*l+n*shiftw:panelw*(l+1)+n*shiftw,i, j], r)\n",
    "                                x_centers[i,q,j] = (panelw*k+m*shiftw+panelw*(k+1)+m*shiftw)/2.\n",
    "                                y_centers[i,q,j] = (panelw*l+n*shiftw+panelw*(l+1)+n*shiftw)/2.\n",
    "                                q+=1\n",
    "                                imgs[:,:,i,q,j] = np.fliplr(np.rot90(data[panelw*k+m*shiftw:panelw*(k+1)+m*shiftw,panelw*l+n*shiftw:panelw*(l+1)+n*shiftw,i, j], r))\n",
    "                                x_centers[i,q,j] = (panelw*k+m*shiftw+panelw*(k+1)+m*shiftw)/2.\n",
    "                                y_centers[i,q,j] = (panelw*l+n*shiftw+panelw*(l+1)+n*shiftw)/2.\n",
    "                                q+=1\n",
    "    return imgs, x_centers, y_centers\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def make_acc_image(acc_grid):\n",
    "    \n",
    "    acc_image = np.zeros((256,256))\n",
    "    \n",
    "    # Bottom row\n",
    "    acc_image[:31,:31] = acc_grid[0]\n",
    "    acc_image[:31,32:63] = acc_grid[1]\n",
    "    acc_image[:31,64:95] = acc_grid[2]\n",
    "    acc_image[:31,96:127] = acc_grid[3]\n",
    "    acc_image[:31,128:159] = acc_grid[4]\n",
    "    acc_image[:31,160:191] = acc_grid[5]\n",
    "    acc_image[:31,192:223] = acc_grid[6]\n",
    "    acc_image[:31,224:255] = acc_grid[7]\n",
    "    \n",
    "    # Next row = 2\n",
    "    acc_image[32:63,:31] = acc_grid[8]\n",
    "    acc_image[32:63,32:63] = acc_grid[9]\n",
    "    acc_image[32:63,64:95] = acc_grid[10]\n",
    "    acc_image[32:63,96:127] = acc_grid[11]\n",
    "    acc_image[32:63,128:159] = acc_grid[12]\n",
    "    acc_image[32:63,160:191] = acc_grid[13]\n",
    "    acc_image[32:63,192:223] = acc_grid[14]\n",
    "    acc_image[32:63,224:255] = acc_grid[15]\n",
    " \n",
    "    # Next row = 3\n",
    "    acc_image[64:95,:31] = acc_grid[16]\n",
    "    acc_image[64:95,32:63] = acc_grid[17]\n",
    "    acc_image[64:95,64:95] = acc_grid[18]\n",
    "    acc_image[64:95,96:127] = acc_grid[19]\n",
    "    acc_image[64:95,128:159] = acc_grid[20]\n",
    "    acc_image[64:95,160:191] = acc_grid[21]\n",
    "    acc_image[64:95,192:223] = acc_grid[22]\n",
    "    acc_image[64:95,224:255] = acc_grid[23]\n",
    "    \n",
    "    \n",
    "    # Next row = 4\n",
    "    acc_image[96:127,:31] = acc_grid[24]\n",
    "    acc_image[96:127,32:63] = acc_grid[25]\n",
    "    acc_image[96:127,64:95] = acc_grid[26]\n",
    "    acc_image[96:127,96:127] = acc_grid[27]\n",
    "    acc_image[96:127,128:159] = acc_grid[28]\n",
    "    acc_image[96:127,160:191] = acc_grid[29]\n",
    "    acc_image[96:127,192:223] = acc_grid[30]\n",
    "    acc_image[96:127,224:255] = acc_grid[31]\n",
    "    \n",
    "    # Next row = 5\n",
    "    acc_image[128:159,:31] = acc_grid[32]\n",
    "    acc_image[128:159,32:63] = acc_grid[33]\n",
    "    acc_image[128:159,64:95] = acc_grid[34]\n",
    "    acc_image[128:159,96:127] = acc_grid[35]\n",
    "    acc_image[128:159,128:159] = acc_grid[36]\n",
    "    acc_image[128:159,160:191] = acc_grid[37]\n",
    "    acc_image[128:159,192:223] = acc_grid[38]\n",
    "    acc_image[128:159,224:255] = acc_grid[39]\n",
    "    \n",
    "     # Next row = 6\n",
    "    acc_image[160:191,:31] = acc_grid[40]\n",
    "    acc_image[160:191,32:63] = acc_grid[41]\n",
    "    acc_image[160:191,64:95] = acc_grid[42]\n",
    "    acc_image[160:191,96:127] = acc_grid[43]\n",
    "    acc_image[160:191,128:159] = acc_grid[44]\n",
    "    acc_image[160:191,160:191] = acc_grid[45]\n",
    "    acc_image[160:191,192:223] = acc_grid[46]\n",
    "    acc_image[160:191,224:255] = acc_grid[47]\n",
    "   \n",
    "     # Next row = 7\n",
    "    acc_image[192:223,:31] = acc_grid[48]\n",
    "    acc_image[192:223,32:63] = acc_grid[49]\n",
    "    acc_image[192:223,64:95] = acc_grid[50]\n",
    "    acc_image[192:223,96:127] = acc_grid[51]\n",
    "    acc_image[192:223,128:159] = acc_grid[52]\n",
    "    acc_image[192:223,160:191] = acc_grid[53]\n",
    "    acc_image[192:223,192:223] = acc_grid[54]\n",
    "    acc_image[192:223,224:255] = acc_grid[55]\n",
    "    \n",
    "    \n",
    "     # Next row = 8\n",
    "    acc_image[224:255,:31] = acc_grid[56]\n",
    "    acc_image[224:255,32:63] = acc_grid[57]\n",
    "    acc_image[224:255,64:95] = acc_grid[58]\n",
    "    acc_image[224:255,96:127] = acc_grid[59]\n",
    "    acc_image[224:255,128:159] = acc_grid[60]\n",
    "    acc_image[224:255,160:191] = acc_grid[61]\n",
    "    acc_image[224:255,192:223] = acc_grid[62]\n",
    "    acc_image[224:255,224:255] = acc_grid[63]\n",
    "     \n",
    "    return acc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the paths to the raw data files\n",
    "whereami = '/home/jhargis'\n",
    "#whereami = '/Users/jhargis'\n",
    "path     = 'Dropbox/astroNN/wl_maps/'\n",
    "#whereami = '/Users/goldston'\n",
    "#whereami = '/Users/jegpeek'\n",
    "#path = 'Documents/Weak_Lensing/kmaps_smoothed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set (1) the factor by which we want to degrade the original WL maps\n",
    "# and (2) the number of realizations of each universe.\n",
    "#\n",
    "#   The original images are 2048 x 2048, and we degrade them using\n",
    "#   an 8 x 8 sq.pix box, which makes a smaller set of 64 images \n",
    "#   (= 256x256 sq.pix in size).\n",
    "\n",
    "degrade=8\n",
    "nct = 9\n",
    "\n",
    "data, labels = read_WL(path,display=True)\n",
    "\n",
    "print \"Data shape :\",data.shape\n",
    "print \"Labels     :\",labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display an example of the full 2048 x 2048 image\n",
    "fullimage = getFITS(\"smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0009r_0029p_0100z_og.gre.fit\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(fullimage, origin=\"lower\")\n",
    "plt.clim(-.015,0.025)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now compare a small section of the original image to the rebinned version\n",
    "#   Becaused we used an 8x8 box, a 256x256 region in the original image\n",
    "#   should correspond to a 32x32 region in the rebinned image\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(fullimage[:256,:256],origin=\"lower\")\n",
    "plt.clim(-0.015,0.025)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "image_data = data[:32,:32,8,1]\n",
    "image_data.shape\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(image_data, origin='lower')\n",
    "plt.clim(-0.015,0.025)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we slice the data in the following manner:\n",
    "#\n",
    "#   1) Each 256 x 256 image is again split 8 x 8 into 64 images which are 32 x 32 sq. pix in size\n",
    "#   2) Series of 4 rotations, 2 flips, and shifts of 2 pixels in size\n",
    "imgs2, x_centers, y_centers = slice_data(data, labels, 3, 3)\n",
    "img2sh = imgs2.shape\n",
    "\n",
    "# Next, reshape the arrays and take the first 7 realizations as the training data set\n",
    "train_dataset = np.transpose(imgs2[:, :, 0:7, :, :].reshape(img2sh[0], img2sh[1], 7.0*img2sh[3]*2.0), (2, 0, 1))\n",
    "train_xc = x_centers[0:7, :, :].reshape(7.0*img2sh[3]*2.0)\n",
    "train_yc = y_centers[0:7, :, :].reshape(7.0*img2sh[3]*2.0)\n",
    "ones = np.ones([7,img2sh[3], 2] )\n",
    "train_labels = ((np.asarray([0,1])).reshape(1, 1, 2)*ones).reshape(7.0*img2sh[3]*2.0)\n",
    "\n",
    "# The validation set is the 8th realization\n",
    "valid_dataset = np.transpose(imgs2[:, :, 7, :, :].reshape(img2sh[0], img2sh[1], 1.0*img2sh[3]*2.0), (2, 0, 1))\n",
    "valid_xc = x_centers[7, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "valid_yc = y_centers[7, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "ones = np.ones([1,img2sh[3], 2] )\n",
    "valid_labels = ((np.asarray([0,1])).reshape(1, 1, 2)*ones).reshape(1.0*img2sh[3]*2.0)\n",
    "\n",
    "# The test data set is the 9th realization\n",
    "test_dataset = np.transpose(imgs2[:, :, 8, :, :].reshape(img2sh[0], img2sh[1], 1.0*img2sh[3]*2.0), (2, 0, 1))\n",
    "test_xc = x_centers[8, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "test_yc = y_centers[8, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "ones = np.ones([1,img2sh[3], 2] )\n",
    "test_labels = ((np.asarray([0,1])).reshape(1, 1, 2)*ones).reshape(1.0*img2sh[3]*2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Master images tensor shape:\", img2sh\n",
    "print\n",
    "print \"Train dataset shape:\", train_dataset.shape\n",
    "print \"Train labels shape :\", train_labels.shape\n",
    "print \"Test dataset shape :\", test_dataset.shape\n",
    "print \"Valid dataset shape:\", valid_dataset.shape\n",
    "print \"TOTAL data sets    : \", train_dataset.shape[0] + test_dataset.shape[0] + valid_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.reshape(x_centers, 9*19720*2), np.reshape(y_centers, 9*19720*2), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "sub1 = plt.subplot(2, 6, 1)\n",
    "sub1.set_xticks(())\n",
    "sub1.set_yticks(())\n",
    "sub1.imshow(image_data, origin='lower')\n",
    "\n",
    "image_data = test_dataset[0,:32,:32]\n",
    "sub2 = plt.subplot(2, 6, 2)\n",
    "sub2.set_xticks(())\n",
    "sub2.set_yticks(())\n",
    "sub2.imshow(image_data, origin='lower')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop to get array elements for grid\n",
    "indv = np.arange(1,1024,2)\n",
    "k = 0\n",
    "test_grid = []\n",
    "for i in range(256):\n",
    "    test_grid.append(indv[k:k+8])\n",
    "    k+=8\n",
    "\n",
    "# Plot the full figure (rebinned)\n",
    "plt.figure(figsize=(12, 6))\n",
    "image_data = data[:,:,8,1]\n",
    "#plt.imshow(fullimage, origin=\"lower\")\n",
    "plt.imshow(image_data, origin=\"lower\")\n",
    "plt.clim(-.015,0.025)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "# Plot based on setup grid\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8,figsize=(10,10))\n",
    "gridpt = 0\n",
    "j = 0\n",
    "print \"test_grid:\",test_grid[gridpt]\n",
    "for ax in axes.flat:\n",
    "    idx = test_grid[gridpt][j]\n",
    "    pldata = test_dataset[idx, :32, :32]\n",
    "    im = ax.imshow(pldata, origin='lower',vmin=-0.015, vmax=0.025)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    j+=1    \n",
    "fig.subplots_adjust(right=1.)\n",
    "#cbar_ax = fig.add_axes(([0.85, 0.15, 0.05, 0.7]))\n",
    "#fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    " \n",
    "# Plot based on setup grid\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8,figsize=(10,10))\n",
    "gridpt = 63\n",
    "j = 0\n",
    "print \"test_grid:\",test_grid[gridpt]\n",
    "for ax in axes.flat:\n",
    "    idx = test_grid[gridpt][j]\n",
    "    pldata = test_dataset[idx, :32, :32]\n",
    "    im = ax.imshow(pldata, origin='lower',vmin=-0.015, vmax=0.025)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    j+=1    \n",
    "fig.subplots_adjust(right=1.)\n",
    "#cbar_ax = fig.add_axes(([0.85, 0.15, 0.05, 0.7]))\n",
    "#fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [],
   "source": [
    "# Just don't even worry about this for now.\n",
    "# Figure it out later.\n",
    "\n",
    "\"\"\"\n",
    "#pickle_file = 'notMNIST.pickle'\n",
    "#pickle_file = '/Users/jegpeek/Documents/WL88.pickle'\n",
    "pickle_file = '/Users/jegpeek/Dropbox/WL_other.pickle'\n",
    "\n",
    "usePickle = True\n",
    "\n",
    "if usePickle:\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      save = pickle.load(f)\n",
    "      train_dataset = save['train_dataset']\n",
    "      train_labels = save['train_labels']\n",
    "      valid_dataset = save['valid_dataset']\n",
    "      valid_labels = save['valid_labels']\n",
    "      test_dataset = save['test_dataset']\n",
    "      test_labels = save['test_labels']\n",
    "      del save  # hint to help gc free up memory\n",
    "      print('Training set', train_dataset.shape, train_labels.shape)\n",
    "      print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "      print('Test set', test_dataset.shape, test_labels.shape)\n",
    "else:\n",
    "    %run Read_WL.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [],
   "source": [
    "# Reformat into a TensorFlow-friendly shape:\n",
    "# - convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "# - labels as float 1-hot encodings.\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 2\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"test_labels:\", test_labels[test_grid[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cut this down to a subset\n",
    "test_frac = 0.3\n",
    "_train_dataset = train_dataset[0:train_dataset.shape[0]*test_frac,:,:,:]\n",
    "_train_labels  = train_labels[0:train_labels.shape[0]*test_frac,:]\n",
    "_test_dataset = test_dataset[0:test_dataset.shape[0]*test_frac,:,:,:]\n",
    "_test_labels  = test_labels[0:test_labels.shape[0]*test_frac,:]\n",
    "_valid_dataset = valid_dataset[0:valid_dataset.shape[0]*test_frac,:,:,:]\n",
    "_valid_labels  = valid_labels[0:valid_labels.shape[0]*test_frac,:]\n",
    "print('--> Using subset <--')\n",
    "#print('Training set', _train_dataset.shape, _train_labels.shape)\n",
    "#print('Validation set', _valid_dataset.shape, _valid_labels.shape)\n",
    "#print('Test set', _test_dataset.shape, _test_labels.shape)\n",
    "train_dataset = _train_dataset\n",
    "train_labels = _train_labels\n",
    "test_dataset = _test_dataset\n",
    "test_labels = _test_labels\n",
    "valid_dataset = _valid_dataset\n",
    "valid_labels = _valid_labels\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 128  # 16\n",
    "patch_size = 5    # 5\n",
    "depth = 32        # 16\n",
    "depth2= 64        # JRH addition\n",
    "num_hidden = 2048   # 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Global Step\n",
    "    #global_step = tf.Variable(1.)\n",
    "    #learn_decay = 0.85\n",
    "    #learning_rate = tf.train.exponential_decay(0.005, global_step, 10000, learn_decay, staircase=True)\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Variables.\n",
    "    #layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    #layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    #layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    #layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    #layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    #layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    #layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    #layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "    # Alternate variable setup\n",
    "    #   Layer 1: Compute 16 features = depth\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    #layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer1_biases = tf.Variable(tf.constant(0.1, shape=[depth]))\n",
    "    \n",
    "    #   Layer 2: Compute 32 features = DEPTH2\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth2], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(0.1, shape=[depth2]))\n",
    "    \n",
    "    #   Layer 3: Fully-connected layer should use depth2, which results from layer2\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth2, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(0.01, shape=[num_hidden]))\n",
    "    \n",
    "    #   Layer 4: Readout layer\n",
    "    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #with tf.name_scope('derp'):\n",
    "    #  spl = tf.split(3, 16, layer1_weights)\n",
    "    #  filter_summary = tf.image_summary((spl[0]).name, spl[0], max_images=1)\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        #  Layer 1\n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        #  Layer 2\n",
    "        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        #  Layer 3 = fully connected\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        #  Layer 4 = readout layer\n",
    "        return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "    def variable_summaries(var, name):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "        tf.scalar_summary('sttdev/' + name, stddev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)\n",
    "        \n",
    "    with tf.name_scope('layer1'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer1_weights, 'layer1/weights')\n",
    "            with tf.name_scope(\"images\"):\n",
    "                spl = tf.split(3, 8, layer1_weights)\n",
    "                tf.image_summary(\"layer1/weights\", spl[0])\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer1_biases, 'layer1/biases')\n",
    "\n",
    "    with tf.name_scope('layer2'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer2_weights, 'layer2/weights')\n",
    "            with tf.name_scope(\"images\"):\n",
    "                spl = tf.split(3, 16, layer2_weights)\n",
    "                tf.image_summary(\"layer2/weights\", spl[0])\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer2_biases, 'layer2/biases')\n",
    "\n",
    "    with tf.name_scope('layer3'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer2_weights, 'layer3/weights')\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer3_biases, 'layer3/biases')\n",
    "            \n",
    "    with tf.name_scope('layer4'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer4_weights, 'layer4/weights')\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer4_biases, 'layer4/biases')\n",
    "            \n",
    "                \n",
    "    with tf.name_scope('loss'):\n",
    "        # Try to log the loss\n",
    "        tf.scalar_summary('loss', loss)\n",
    "        \n",
    "    with tf.name_scope('learning_rate'):\n",
    "        tf.scalar_summary('learning_rate', learning_rate)\n",
    "                \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "    merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_prediction.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(train_labels.shape[0])\n",
    "train_dataset = train_dataset[permutation,:,:]\n",
    "train_labels = train_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628"
   },
   "outputs": [],
   "source": [
    "# Run of TensorFlow without the permutations\n",
    "# but with the TensorBoard logging calls\n",
    "num_steps = 200001\n",
    "print_step = 200\n",
    "summary_step = 200\n",
    "losses = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_valid = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_test = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_train = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_grid = np.zeros(64)\n",
    "acc_image = np.zeros((256,256))\n",
    "q = 0\n",
    "p = 0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    summary_writer = tf.train.SummaryWriter(whereami+'/Documents/logs', session.graph_def)\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        summary, _, l, predictions = session.run([merged, optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        if (step % print_step == 0):\n",
    "            losses[q] = l\n",
    "            test_prediction_results = test_prediction.eval()\n",
    "            acc_valid[q] = accuracy(valid_prediction.eval(), valid_labels)/100.0\n",
    "            acc_test[q] = accuracy(test_prediction_results, test_labels)/100.0\n",
    "            acc_train[q] = accuracy(predictions, batch_labels)/100.0\n",
    "            for i in range(len(acc_grid)):\n",
    "                acc_grid[i] = accuracy(test_prediction_results[test_grid[i]], test_labels[test_grid[i]])/100.0\n",
    "            q += 1\n",
    "            \n",
    "            # Setup the plot\n",
    "            #fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(10,7))\n",
    "            fig = plt.figure(figsize=(10,7))\n",
    "            ax1 = plt.subplot2grid((2,2),(0,0),colspan=2)\n",
    "            ax2 = plt.subplot2grid((2,2),(1,0))\n",
    "            ax3 = plt.subplot2grid((2,2),(1,1))\n",
    "            \n",
    "            ax1.plot(np.arange(0,(num_steps-1)/print_step+1), acc_valid, '.', color='b',alpha=0.5)\n",
    "            ax1.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),acc_test, '.', color='g',alpha=0.5)\n",
    "            ax1.plot(np.arange(0,(num_steps-1)/print_step+1), acc_train, '.', color='r',alpha=0.5)\n",
    "            ax1.set_ylim([0.45, 1.05])\n",
    "            #plt.xlim([-1000, 1000])\n",
    "            ax1.set_xlim([-1*((step/print_step)*1.1),(step/print_step)*1.1])\n",
    "            #plt.xlim([-1*(((num_steps-1)/print_step+1)*1.1),((num_steps-1)/print_step+1)*1.1])\n",
    "            \n",
    "            # Plot the accuracy grid\n",
    "            acc_image = make_acc_image(acc_grid)\n",
    "            #fig = plt.figure(figsize=(12, 6))\n",
    "            #sub1 = plt.subplot(1, 2, 1)\n",
    "            ax2.set_xticks(())\n",
    "            ax2.set_yticks(())\n",
    "            im2 = ax2.imshow(acc_image, origin='lower',vmin = 0, vmax = 1.0)\n",
    "            divider2 = make_axes_locatable(ax2)\n",
    "            cim2 = divider2.append_axes(\"right\", size=\"20%\", pad=0.5)\n",
    "            cbar2 = plt.colorbar(im2, cax=cim2, ticks=MultipleLocator(0.2), format=\"%.2f\")\n",
    "            #sub2 = plt.subplot(1, 2, 2)\n",
    "            ax3.set_xticks(())\n",
    "            ax3.set_yticks(())\n",
    "            im3 = ax3.imshow(image_data, origin='lower',vmin = -0.015, vmax = 0.025)\n",
    "            divider3 = make_axes_locatable(ax3)\n",
    "            cim3 = divider3.append_axes(\"right\", size=\"20%\", pad=0.5)\n",
    "            cbar3 = plt.colorbar(im3, cax=cim3, ticks=MultipleLocator(0.2))\n",
    "\n",
    "            \n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            print('Minibatch loss at step %d: %f (%.3f sec)' % (step, l, duration))\n",
    "            #print('  Grid point acc:',acc_grid[0], acc_grid[1], acc_grid[2], acc_grid[3], acc_grid[4], acc_grid[5], acc_grid[6], acc_grid[7])\n",
    "            #print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            #print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "        if (step % summary_step == 0):\n",
    "            #print \"got here\"\n",
    "            summary_writer.add_summary(summary, p)\n",
    "            p += 1\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# permutation = np.random.permutation(train_labels.shape[0])\n",
    "#train_dataset = train_dataset[permutation,:,:]\n",
    "#train_labels = train_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_prediction_results[test_grid[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels[test_grid[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy(test_prediction_results[test_grid[0]],test_labels[test_grid[0]])/100.\n",
    "acc_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "num_steps = 20001\n",
    "print_step = 200\n",
    "losses = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_valid = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_test = np.zeros((num_steps-1)/print_step+1)\n",
    "q = 0\n",
    "p=0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % print_step == 0):\n",
    "            losses[q] = l\n",
    "            acc_valid[q] = accuracy(valid_prediction.eval(), valid_labels)/100.0\n",
    "            acc_test[q] = accuracy(test_prediction.eval(), test_labels)/100.0\n",
    "            q += 1\n",
    "            plt.plot(np.arange(0,(num_steps-1)/print_step+1), acc_valid, '.', color='b')\n",
    "            plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),acc_test, '.', color='g')\n",
    "            plt.ylim([0.45, 0.65])\n",
    "            plt.xlim([-1000, 1000])\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            #print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            #print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.plot(np.arange(0,(num_steps-1)/print_step+1), acc_valid, '.', color='b')\n",
    "plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),acc_test, '.', color='g')\n",
    "plt.ylim([0.45, 0.75])\n",
    "plt.xlim([-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(acc_test, acc_valid, '.', color='b')\n",
    "#plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),losses, '.', color='g')\n",
    "plt.ylim([0.4, 0.7])\n",
    "plt.xlim([0.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open questions:**\n",
    "+ Why is there so much scatter in the loss function over time?\n",
    "+ Is there structure in the loss function over time?\n",
    "+ If I plot loss vs. accuracy, what do I get? \n",
    "+ Do I really see a difference when I scramble vs. leave in order, and if so, is it because of the way SGD interacts with the two cosmologies?\n",
    "+ will deeper / better networks get us over 65%?\n",
    "+ Why, oh why, are my test and valid data sets so damn well correlated??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "graph.get_tensor_by_name.im_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
