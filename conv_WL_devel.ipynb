{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Investigating using Convolutional Networks on Weak Lensing data\n",
    "=============\n",
    "\n",
    "Adapted from 4_conv_WL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "%matplotlib inline\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reorganize the code a bit by putting the function definitions first.\n",
    "def rebin(a, shape):\n",
    "    sh = shape[0],a.shape[0]//shape[0],shape[1],a.shape[1]//shape[1]\n",
    "    return a.reshape(sh).mean(-1).mean(1)\n",
    "\n",
    "def getFITS(imagename):\n",
    "    filename = whereami + '/' + path + imagename\n",
    "    f = fits.open(filename)\n",
    "    dataout = f[0].data\n",
    "    \n",
    "    return dataout\n",
    "\n",
    "def read_WL(path,display=None):\n",
    "    # this is a version to look at sigma8\n",
    "    labels=['750', '850']\n",
    "    imgs = np.zeros([2048/degrade, 2048/degrade, nct, len(labels)])\n",
    "    for j, label in enumerate(labels):\n",
    "        for i in range(nct):\n",
    "            filename = whereami + '/' + path + 'smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.'+label+'_4096xy_000'+ np.str(i+1) +'r_0029p_0100z_og.gre.fit'\n",
    "            if display: print(\"i: %d  j: %d  name: %s\" % (i, j, 'smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.'+label+'_4096xy_000'+ np.str(i+1) +'r_0029p_0100z_og.gre.fit'))\n",
    "            f = fits.open(filename)\n",
    "            imgs[:,:,i,j]=rebin(f[0].data, [2048/degrade, 2048/degrade])\n",
    "            \n",
    "    return imgs, labels\n",
    "\n",
    "def slice_data(data, labels, exp_cut, exp_nshift):\n",
    "    labels=['750', '850']\n",
    "    # how many panels across\n",
    "    npanelx = 2**exp_cut\n",
    "    # and how big are they?\n",
    "    panelw = 2048/(degrade*npanelx)\n",
    "    # how many shifted panels?\n",
    "    nshift = 2**exp_nshift -1\n",
    "    # and what are the shifts?\n",
    "    shiftw =  panelw/2**exp_nshift\n",
    "    # with 4 rotations, and 2 shifts, we have\n",
    "    imgs = np.zeros([panelw, panelw, nct,(npanelx**2 +(npanelx-1)**2*nshift**2)*8, len(labels)])\n",
    "    # let's figure out where the centers are, and save that data\n",
    "    x_centers = np.zeros([nct,(npanelx**2 +(npanelx-1)**2*nshift**2)*8, len(labels)])\n",
    "    y_centers = np.zeros([nct,(npanelx**2 +(npanelx-1)**2*nshift**2)*8, len(labels)])\n",
    "    for j, label in enumerate(labels):\n",
    "        for i in range(nct):\n",
    "            q=0\n",
    "            for k in range(npanelx):\n",
    "                for l in range(npanelx):\n",
    "                    for r in range(4):\n",
    "                        imgs[:,:,i,q,j] = np.rot90(data[panelw*k:panelw*(k+1),panelw*l:panelw*(l+1),i, j], r)\n",
    "                        x_centers[i,q,j] = (panelw*k+panelw*(k+1))/2.\n",
    "                        y_centers[i,q,j] = (panelw*l+panelw*(l+1))/2.\n",
    "                        q+=1\n",
    "                        imgs[:,:,i,q,j] = np.fliplr(np.rot90(data[panelw*k:panelw*(k+1),panelw*l:panelw*(l+1),i, j], r))\n",
    "                        x_centers[i,q,j] = (panelw*k+panelw*(k+1))/2.\n",
    "                        y_centers[i,q,j] = (panelw*l+panelw*(l+1))/2.\n",
    "                        q+=1\n",
    "            for k in range(npanelx-1):\n",
    "                for l in range(npanelx-1):\n",
    "                    for m in range(nshift):\n",
    "                        for n in range(nshift):\n",
    "                            for r in range(4):\n",
    "                                imgs[:,:,i,q,j] = np.rot90(data[panelw*k+m*shiftw:panelw*(k+1)+m*shiftw,panelw*l+n*shiftw:panelw*(l+1)+n*shiftw,i, j], r)\n",
    "                                x_centers[i,q,j] = (panelw*k+m*shiftw+panelw*(k+1)+m*shiftw)/2.\n",
    "                                y_centers[i,q,j] = (panelw*l+n*shiftw+panelw*(l+1)+n*shiftw)/2.\n",
    "                                q+=1\n",
    "                                imgs[:,:,i,q,j] = np.fliplr(np.rot90(data[panelw*k+m*shiftw:panelw*(k+1)+m*shiftw,panelw*l+n*shiftw:panelw*(l+1)+n*shiftw,i, j], r))\n",
    "                                x_centers[i,q,j] = (panelw*k+m*shiftw+panelw*(k+1)+m*shiftw)/2.\n",
    "                                y_centers[i,q,j] = (panelw*l+n*shiftw+panelw*(l+1)+n*shiftw)/2.\n",
    "                                q+=1\n",
    "    return imgs, x_centers, y_centers\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the paths to the raw data files\n",
    "#whereami = '/home/jhargis'\n",
    "whereami = '/Users/jhargis'\n",
    "path     = 'Dropbox/astroNN/wl_maps/'\n",
    "#whereami = '/Users/goldston'\n",
    "#whereami = '/Users/jegpeek'\n",
    "#path = 'Documents/Weak_Lensing/kmaps_smoothed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0001r_0029p_0100z_og.gre.fit\n",
      "i: 1  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0002r_0029p_0100z_og.gre.fit\n",
      "i: 2  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0003r_0029p_0100z_og.gre.fit\n",
      "i: 3  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0004r_0029p_0100z_og.gre.fit\n",
      "i: 4  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0005r_0029p_0100z_og.gre.fit\n",
      "i: 5  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0006r_0029p_0100z_og.gre.fit\n",
      "i: 6  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0007r_0029p_0100z_og.gre.fit\n",
      "i: 7  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0008r_0029p_0100z_og.gre.fit\n",
      "i: 8  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0009r_0029p_0100z_og.gre.fit\n",
      "i: 0  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0001r_0029p_0100z_og.gre.fit\n",
      "i: 1  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0002r_0029p_0100z_og.gre.fit\n",
      "i: 2  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0003r_0029p_0100z_og.gre.fit\n",
      "i: 3  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0004r_0029p_0100z_og.gre.fit\n",
      "i: 4  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0005r_0029p_0100z_og.gre.fit\n",
      "i: 5  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0006r_0029p_0100z_og.gre.fit\n",
      "i: 6  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0007r_0029p_0100z_og.gre.fit\n",
      "i: 7  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0008r_0029p_0100z_og.gre.fit\n",
      "i: 8  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0009r_0029p_0100z_og.gre.fit\n",
      "Data shape : (256, 256, 9, 2)\n",
      "Labels     : ['750', '850']\n"
     ]
    }
   ],
   "source": [
    "# Set (1) the factor by which we want to degrade the original WL maps\n",
    "# and (2) the number of realizations of each universe.\n",
    "#\n",
    "#   The original images are 2048 x 2048, and we degrade them using\n",
    "#   an 8 x 8 sq.pix box, which makes a smaller set of 64 images \n",
    "#   (= 256x256 sq.pix in size).\n",
    "\n",
    "degrade=8\n",
    "nct = 9\n",
    "\n",
    "data, labels = read_WL(path,display=True)\n",
    "\n",
    "print \"Data shape :\",data.shape\n",
    "print \"Labels     :\",labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display an example of the full 2048 x 2048 image\n",
    "#fullimage = getFITS(\"smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0001r_0029p_0100z_og.gre.fit\")\n",
    "#plt.imshow(fullimage, origin=\"lower\")\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now compare a small section of the original image to the rebinned version\n",
    "#   Becaused we used an 8x8 box, a 256x256 region in the original image\n",
    "#   should correspond to a 32x32 region in the rebinned image\n",
    "#plt.imshow(fullimage[:256,:256],origin=\"lower\")\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "\n",
    "#image_data = data[:32,:32,0,0]\n",
    "#image_data.shape\n",
    "#plt.imshow(image_data, origin='lower')\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:13: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:16: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:23: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:25: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:27: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# First we slice the data in the following manner:\n",
    "#\n",
    "#   1) Each 256 x 256 image is again split 8 x 8 into 64 images which are 32 x 32 sq. pix in size\n",
    "#   2) Series of 4 rotations, 2 flips, and shifts of 2 pixels in size\n",
    "imgs2, x_centers, y_centers = slice_data(data, labels, 3, 3)\n",
    "img2sh = imgs2.shape\n",
    "\n",
    "# Next, reshape the arrays and take the first 7 realizations as the training data set\n",
    "train_dataset = np.transpose(imgs2[:, :, 0:7, :, :].reshape(img2sh[0], img2sh[1], 7.0*img2sh[3]*2.0), (2, 0, 1))\n",
    "train_xc = x_centers[0:7, :, :].reshape(7.0*img2sh[3]*2.0)\n",
    "train_yc = y_centers[0:7, :, :].reshape(7.0*img2sh[3]*2.0)\n",
    "ones = np.ones([7,img2sh[3], 2] )\n",
    "train_labels = ((np.asarray([0,1])).reshape(1, 1, 2)*ones).reshape(7.0*img2sh[3]*2.0)\n",
    "\n",
    "# The validation set is the 8th realization\n",
    "valid_dataset = np.transpose(imgs2[:, :, 7, :, :].reshape(img2sh[0], img2sh[1], 1.0*img2sh[3]*2.0), (2, 0, 1))\n",
    "valid_xc = x_centers[7, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "valid_yc = y_centers[7, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "ones = np.ones([1,img2sh[3], 2] )\n",
    "valid_labels = ((np.asarray([0,1])).reshape(1, 1, 2)*ones).reshape(1.0*img2sh[3]*2.0)\n",
    "\n",
    "# The test data set is the 9th realization\n",
    "test_dataset = np.transpose(imgs2[:, :, 8, :, :].reshape(img2sh[0], img2sh[1], 1.0*img2sh[3]*2.0), (2, 0, 1))\n",
    "test_xc = x_centers[8, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "test_yc = y_centers[8, :, :].reshape(1.0*img2sh[3]*2.0)\n",
    "ones = np.ones([1,img2sh[3], 2] )\n",
    "test_labels = ((np.asarray([0,1])).reshape(1, 1, 2)*ones).reshape(1.0*img2sh[3]*2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master images tensor shape: (32, 32, 9, 19720, 2)\n",
      "\n",
      "Train dataset shape: (276080, 32, 32)\n",
      "Train labels shape : (276080,)\n",
      "Test dataset shape : (39440, 32, 32)\n",
      "Valid dataset shape: (39440, 32, 32)\n",
      "TOTAL data sets    :  354960\n"
     ]
    }
   ],
   "source": [
    "print \"Master images tensor shape:\", img2sh\n",
    "print\n",
    "print \"Train dataset shape:\", train_dataset.shape\n",
    "print \"Train labels shape :\", train_labels.shape\n",
    "print \"Test dataset shape :\", test_dataset.shape\n",
    "print \"Valid dataset shape:\", valid_dataset.shape\n",
    "print \"TOTAL data sets    : \", train_dataset.shape[0] + test_dataset.shape[0] + valid_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1163a7310>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6EvSjFj0JWlGLPqSNCP/D76+BEMbBYhxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114f90f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.reshape(x_centers, 9*19720*2), np.reshape(y_centers, 9*19720*2), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#pickle_file = 'notMNIST.pickle'\\n#pickle_file = '/Users/jegpeek/Documents/WL88.pickle'\\npickle_file = '/Users/jegpeek/Dropbox/WL_other.pickle'\\n\\nusePickle = True\\n\\nif usePickle:\\n    with open(pickle_file, 'rb') as f:\\n      save = pickle.load(f)\\n      train_dataset = save['train_dataset']\\n      train_labels = save['train_labels']\\n      valid_dataset = save['valid_dataset']\\n      valid_labels = save['valid_labels']\\n      test_dataset = save['test_dataset']\\n      test_labels = save['test_labels']\\n      del save  # hint to help gc free up memory\\n      print('Training set', train_dataset.shape, train_labels.shape)\\n      print('Validation set', valid_dataset.shape, valid_labels.shape)\\n      print('Test set', test_dataset.shape, test_labels.shape)\\nelse:\\n    %run Read_WL.py\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just don't even worry about this for now.\n",
    "# Figure it out later.\n",
    "\n",
    "\"\"\"\n",
    "#pickle_file = 'notMNIST.pickle'\n",
    "#pickle_file = '/Users/jegpeek/Documents/WL88.pickle'\n",
    "pickle_file = '/Users/jegpeek/Dropbox/WL_other.pickle'\n",
    "\n",
    "usePickle = True\n",
    "\n",
    "if usePickle:\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "      save = pickle.load(f)\n",
    "      train_dataset = save['train_dataset']\n",
    "      train_labels = save['train_labels']\n",
    "      valid_dataset = save['valid_dataset']\n",
    "      valid_labels = save['valid_labels']\n",
    "      test_dataset = save['test_dataset']\n",
    "      test_labels = save['test_labels']\n",
    "      del save  # hint to help gc free up memory\n",
    "      print('Training set', train_dataset.shape, train_labels.shape)\n",
    "      print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "      print('Test set', test_dataset.shape, test_labels.shape)\n",
    "else:\n",
    "    %run Read_WL.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (276080, 32, 32, 1), (276080, 2))\n",
      "('Validation set', (39440, 32, 32, 1), (39440, 2))\n",
      "('Test set', (39440, 32, 32, 1), (39440, 2))\n"
     ]
    }
   ],
   "source": [
    "# Reformat into a TensorFlow-friendly shape:\n",
    "# - convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "# - labels as float 1-hot encodings.\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 2\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Using subset <--\n",
      "('Training set', (82824, 32, 32, 1), (82824, 2))\n",
      "('Validation set', (11832, 32, 32, 1), (11832, 2))\n",
      "('Test set', (11832, 32, 32, 1), (11832, 2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Cut this down to a subset\n",
    "test_frac = 0.3\n",
    "_train_dataset = train_dataset[0:train_dataset.shape[0]*test_frac,:,:,:]\n",
    "_train_labels  = train_labels[0:train_labels.shape[0]*test_frac,:]\n",
    "_test_dataset = test_dataset[0:test_dataset.shape[0]*test_frac,:,:,:]\n",
    "_test_labels  = test_labels[0:test_labels.shape[0]*test_frac,:]\n",
    "_valid_dataset = valid_dataset[0:valid_dataset.shape[0]*test_frac,:,:,:]\n",
    "_valid_labels  = valid_labels[0:valid_labels.shape[0]*test_frac,:]\n",
    "print('--> Using subset <--')\n",
    "#print('Training set', _train_dataset.shape, _train_labels.shape)\n",
    "#print('Validation set', _valid_dataset.shape, _valid_labels.shape)\n",
    "#print('Test set', _test_dataset.shape, _test_labels.shape)\n",
    "train_dataset = _train_dataset\n",
    "train_labels = _train_labels\n",
    "test_dataset = _test_dataset\n",
    "test_labels = _test_labels\n",
    "valid_dataset = _valid_dataset\n",
    "valid_labels = _valid_labels\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 128  # 16\n",
    "patch_size = 5    # 5\n",
    "depth = 32        # 16\n",
    "depth2= 64        # JRH addition\n",
    "num_hidden = 2048   # 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Global Step\n",
    "    #global_step = tf.Variable(1.)\n",
    "    #learn_decay = 0.85\n",
    "    #learning_rate = tf.train.exponential_decay(0.005, global_step, 10000, learn_decay, staircase=True)\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Variables.\n",
    "    #layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    #layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    #layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    #layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    #layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    #layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    #layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    #layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "    # Alternate variable setup\n",
    "    #   Layer 1: Compute 16 features = depth\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    #layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer1_biases = tf.Variable(tf.constant(0.1, shape=[depth]))\n",
    "    \n",
    "    #   Layer 2: Compute 32 features = DEPTH2\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth2], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(0.1, shape=[depth2]))\n",
    "    \n",
    "    #   Layer 3: Fully-connected layer should use depth2, which results from layer2\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth2, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(0.01, shape=[num_hidden]))\n",
    "    \n",
    "    #   Layer 4: Readout layer\n",
    "    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(0.01, shape=[num_labels]))\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #with tf.name_scope('derp'):\n",
    "    #  spl = tf.split(3, 16, layer1_weights)\n",
    "    #  filter_summary = tf.image_summary((spl[0]).name, spl[0], max_images=1)\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        #  Layer 1\n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        #  Layer 2\n",
    "        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        #  Layer 3 = fully connected\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        #  Layer 4 = readout layer\n",
    "        return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "    def variable_summaries(var, name):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "        tf.scalar_summary('sttdev/' + name, stddev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)\n",
    "        \n",
    "    with tf.name_scope('layer1'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer1_weights, 'layer1/weights')\n",
    "            with tf.name_scope(\"images\"):\n",
    "                spl = tf.split(3, 8, layer1_weights)\n",
    "                tf.image_summary(\"layer1/weights\", spl[0])\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer1_biases, 'layer1/biases')\n",
    "\n",
    "    with tf.name_scope('layer2'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer2_weights, 'layer2/weights')\n",
    "            with tf.name_scope(\"images\"):\n",
    "                spl = tf.split(3, 16, layer2_weights)\n",
    "                tf.image_summary(\"layer2/weights\", spl[0])\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer2_biases, 'layer2/biases')\n",
    "\n",
    "    with tf.name_scope('layer3'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer2_weights, 'layer3/weights')\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer3_biases, 'layer3/biases')\n",
    "            \n",
    "    with tf.name_scope('layer4'):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            variable_summaries(layer4_weights, 'layer4/weights')\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            variable_summaries(layer4_biases, 'layer4/biases')\n",
    "            \n",
    "                \n",
    "    with tf.name_scope('loss'):\n",
    "        # Try to log the loss\n",
    "        tf.scalar_summary('loss', loss)\n",
    "        \n",
    "    with tf.name_scope('learning_rate'):\n",
    "        tf.scalar_summary('learning_rate', learning_rate)\n",
    "                \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "    merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(train_labels.shape[0])\n",
    "train_dataset = train_dataset[permutation,:,:]\n",
    "train_labels = train_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD7CAYAAACc26SuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1165149d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 85200: 0.296308 (0.149 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bdd365b72e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhargis/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD7CAYAAACc26SuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1165149d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run of TensorFlow without the permutations\n",
    "# but with the TensorBoard logging calls\n",
    "num_steps = 200001\n",
    "print_step = 200\n",
    "summary_step = 200\n",
    "losses = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_valid = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_test = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_train = np.zeros((num_steps-1)/print_step+1)\n",
    "q = 0\n",
    "p = 0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    summary_writer = tf.train.SummaryWriter(whereami+'/Documents/logs', session.graph_def)\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        summary, _, l, predictions = session.run([merged, optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        if (step % print_step == 0):\n",
    "            losses[q] = l\n",
    "            acc_valid[q] = accuracy(valid_prediction.eval(), valid_labels)/100.0\n",
    "            acc_test[q] = accuracy(test_prediction.eval(), test_labels)/100.0\n",
    "            acc_train[q] = accuracy(predictions, batch_labels)/100.0\n",
    "            q += 1\n",
    "            plt.plot(np.arange(0,(num_steps-1)/print_step+1), acc_valid, '.', color='b',alpha=0.5)\n",
    "            plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),acc_test, '.', color='g',alpha=0.5)\n",
    "            plt.plot(np.arange(0,(num_steps-1)/print_step+1), acc_train, '.', color='r',alpha=0.5)\n",
    "            plt.ylim([0.45, 1.05])\n",
    "            #plt.xlim([-1000, 1000])\n",
    "            plt.xlim([-1*((step/print_step)*1.1),(step/print_step)*1.1])\n",
    "            #plt.xlim([-1*(((num_steps-1)/print_step+1)*1.1),((num_steps-1)/print_step+1)*1.1])\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            print('Minibatch loss at step %d: %f (%.3f sec)' % (step, l, duration))\n",
    "            #print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            #print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "        if (step % summary_step == 0):\n",
    "            #print \"got here\"\n",
    "            summary_writer.add_summary(summary, p)\n",
    "            p += 1\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# permutation = np.random.permutation(train_labels.shape[0])\n",
    "#train_dataset = train_dataset[permutation,:,:]\n",
    "#train_labels = train_labels[permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "num_steps = 20001\n",
    "print_step = 200\n",
    "losses = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_valid = np.zeros((num_steps-1)/print_step+1)\n",
    "acc_test = np.zeros((num_steps-1)/print_step+1)\n",
    "q = 0\n",
    "p=0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % print_step == 0):\n",
    "            losses[q] = l\n",
    "            acc_valid[q] = accuracy(valid_prediction.eval(), valid_labels)/100.0\n",
    "            acc_test[q] = accuracy(test_prediction.eval(), test_labels)/100.0\n",
    "            q += 1\n",
    "            plt.plot(np.arange(0,(num_steps-1)/print_step+1), acc_valid, '.', color='b')\n",
    "            plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),acc_test, '.', color='g')\n",
    "            plt.ylim([0.45, 0.65])\n",
    "            plt.xlim([-1000, 1000])\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            #print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            #print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.plot(np.arange(0,(num_steps-1)/print_step+1), acc_valid, '.', color='b')\n",
    "plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),acc_test, '.', color='g')\n",
    "plt.ylim([0.45, 0.75])\n",
    "plt.xlim([-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(acc_test, acc_valid, '.', color='b')\n",
    "#plt.plot((-1)*np.arange(0,(num_steps-1)/print_step+1),losses, '.', color='g')\n",
    "plt.ylim([0.4, 0.7])\n",
    "plt.xlim([0.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open questions:**\n",
    "+ Why is there so much scatter in the loss function over time?\n",
    "+ Is there structure in the loss function over time?\n",
    "+ If I plot loss vs. accuracy, what do I get? \n",
    "+ Do I really see a difference when I scramble vs. leave in order, and if so, is it because of the way SGD interacts with the two cosmologies?\n",
    "+ will deeper / better networks get us over 65%?\n",
    "+ Why, oh why, are my test and valid data sets so damn well correlated??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "graph.get_tensor_by_name.im_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
